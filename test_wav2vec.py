import os
import torch
import h5py
import soundfile as sf
import numpy as np
from tqdm import tqdm
from multiprocessing import Process, Queue
from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor
import torchaudio.functional as F
from queue import Empty

# ğŸ§ª ä¿®æ”¹é€™å€‹è³‡æ–™å¤¾è·¯å¾‘
AUDIO_FOLDER = "./"
MODEL_CKPT = "./pretrained_models/wav2vec2-xls-r-300m"
OUTPUT_PATH = "./test_output.h5"

def worker(audio_queue, result_queue, sample_rate):
    print("[âœ… Worker] Started")
    while True:
        item = audio_queue.get()
        if item is None:
            break
        file_path = item
        try:
            waveform, sr = sf.read(file_path)
            if sr != sample_rate:
                waveform = F.resample(torch.tensor(waveform).float(), orig_freq=sr, new_freq=sample_rate).numpy()

            if waveform.size == 0 or np.max(np.abs(waveform)) == 0:
                print(f"[âš ï¸ Skip] {file_path} is empty or silence")
                continue

            waveform = waveform / np.max(np.abs(waveform))
            waveform = waveform.reshape(1, -1)[0].astype(np.float32)

            uid = os.path.splitext(os.path.basename(file_path))[0]
            result_queue.put((uid, waveform))
            print(f"[ğŸ“¤ Worker] Sent {uid} to result_queue")
        except Exception as e:
            print(f"[âŒ Worker Error] {file_path}: {e}")

def model_proc(result_queue, output_queue, model_ckpt, target_layers, sample_rate):
    print("[âœ… Model] Started")
    processor = Wav2Vec2FeatureExtractor.from_pretrained(model_ckpt)
    model = Wav2Vec2Model.from_pretrained(model_ckpt, output_hidden_states=True).cuda().eval()

    while True:
        item = result_queue.get()
        if item is None:
            break
        uid, waveform = item
        try:
            inputs = processor(waveform, sampling_rate=sample_rate, return_tensors="pt", padding=True)
            input_values = inputs.input_values.cuda()
            attention_mask = inputs.attention_mask.cuda()

            with torch.no_grad():
                outputs = model(input_values, attention_mask=attention_mask)

            features = {}
            for layer_id in target_layers:
                hs = outputs.hidden_states[layer_id].squeeze(0).cpu().half().numpy()
                features[f"layer_{layer_id}"] = hs

            output_queue.put((uid, features))
            print(f"[ğŸ“¤ Model] Put {uid} into output_queue")
        except Exception as e:
            print(f"[âŒ Model Error] {uid}: {e}")
        finally:
            print("[âœ… Model] Sending sentinel to output_queue", flush=True)
            output_queue.put(None)
            print("[âœ… Model] Exiting model process", flush=True)
            return  # <--- æ˜ç¢ºé€€å‡ºæ¨¡å‹é€²ç¨‹

    output_queue.put(None)

def main():
    sample_rate = 16000
    target_layers = [19, 20, 23]

    audio_files = sorted([
        os.path.join(AUDIO_FOLDER, f)
        for f in os.listdir(AUDIO_FOLDER)
        if f.endswith(".wav")
    ])[:1]  # åªå–ä¸€ç­†

    if not audio_files:
        print("[âŒ] æ²’æœ‰æ‰¾åˆ°ä»»ä½• .wav æª”æ¡ˆ")
        return

    audio_queue = Queue()
    result_queue = Queue()
    output_queue = Queue()

    audio_queue.put(audio_files[0])
    audio_queue.put(None)

    w = Process(target=worker, args=(audio_queue, result_queue, sample_rate))
    m = Process(target=model_proc, args=(result_queue, output_queue, MODEL_CKPT, target_layers, sample_rate))

    w.start()
    m.start()

    with h5py.File(OUTPUT_PATH, "w") as h5f:
        while True:
            try:
                item = output_queue.get(timeout=10)
            except Empty:
                print("[â³ Main] Waiting for model output...")
                continue
            finally:
                print("[âœ… Model] Sending sentinel to output_queue", flush=True)
                output_queue.put(None)
            if item is None:
                print("[âœ… Main] Received model sentinel, done.")
                break
            uid, features = item
            print(f"[âœ… Save] Writing {uid}")
            grp = h5f.create_group(uid)
            for layer, data in features.items():
                grp.create_dataset(layer, data=data, compression="gzip")

    w.join()
    m.join()
    print("[âœ… All Done]")

if __name__ == "__main__":
    # main()
    file_path = "E:\\datasets/Asvspoof2019_LA\\test\\audio\\LA_E_1903269.flac"  # æ›¿æ›ç‚ºä½ çš„æª”æ¡ˆè·¯å¾‘
    try:
        waveform, sr = sf.read(file_path)
        print(f"[DEBUG] type={type(waveform)} | shape={getattr(waveform, 'shape', 'N/A')} | dtype={getattr(waveform, 'dtype', 'N/A')}")
        print(f"[DEBUG] waveform[:5] = {waveform[:5]}")
    except Exception as e:
        print(f"[âŒ Error] {file_path}: {e}")
